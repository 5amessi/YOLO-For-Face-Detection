{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YoloV2 Face Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/5amessi/YOLO-For-Face-Detection/blob/master/YoloV2_Face_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK4Z7usLj4Rc",
        "colab_type": "code",
        "outputId": "04fc33b1-ec53-4849-b4e1-9dc8d4f980f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xpoE0ttlCDD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "49bce84e-1527-4ff6-d4d4-39a54f4b34b0"
      },
      "source": [
        "!wget http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/support/bbx_annotation/wider_face_split.zip\n",
        "!wget http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/support/example/Submission_example.zip\n",
        "import zipfile\n",
        "path = \"/content/drive/My Drive/WIDER_train.zip\"\n",
        "zip_ref = zipfile.ZipFile(path, 'r')\n",
        "zip_ref.extractall(\"\")\n",
        "zip_ref.close()\n",
        "path = \"/content/wider_face_split.zip\"\n",
        "zip_ref = zipfile.ZipFile(path, 'r')\n",
        "zip_ref.extractall(\"\")\n",
        "zip_ref.close()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-01 23:08:19--  http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/support/bbx_annotation/wider_face_split.zip\n",
            "Resolving mmlab.ie.cuhk.edu.hk (mmlab.ie.cuhk.edu.hk)... 137.189.99.12\n",
            "Connecting to mmlab.ie.cuhk.edu.hk (mmlab.ie.cuhk.edu.hk)|137.189.99.12|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3591642 (3.4M) [application/zip]\n",
            "Saving to: ‘wider_face_split.zip’\n",
            "\n",
            "\rwider_face_split.zi   0%[                    ]       0  --.-KB/s               \rwider_face_split.zi 100%[===================>]   3.42M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-02-01 23:08:20 (29.6 MB/s) - ‘wider_face_split.zip’ saved [3591642/3591642]\n",
            "\n",
            "--2020-02-01 23:08:23--  http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/support/example/Submission_example.zip\n",
            "Resolving mmlab.ie.cuhk.edu.hk (mmlab.ie.cuhk.edu.hk)... 137.189.99.12\n",
            "Connecting to mmlab.ie.cuhk.edu.hk (mmlab.ie.cuhk.edu.hk)|137.189.99.12|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 624 [application/zip]\n",
            "Saving to: ‘Submission_example.zip’\n",
            "\n",
            "Submission_example. 100%[===================>]     624  --.-KB/s    in 0s      \n",
            "\n",
            "2020-02-01 23:08:23 (124 MB/s) - ‘Submission_example.zip’ saved [624/624]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Grvf_mCEoGls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import libs\n",
        "import os\n",
        "import os.path as path\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.utils import *\n",
        "from keras import backend as K\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from keras import regularizers, optimizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.applications import VGG19 ,inception_v3\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu69NYfHoP44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "baseMapNum = 32\n",
        "weight_decay = 1e-4\n",
        "# ANCHORS = [0.57273, 0.677385]\n",
        "ANCHORS = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]\n",
        "BOX = 5\n",
        "GRID_H = GRID_W = 13\n",
        "BATCH_SIZE = 4\n",
        "IMAGE_H, IMAGE_W = 440,440\n",
        "OBJ_THRESHOLD    = 0.5\n",
        "NMS_THRESHOLD    = 0.5\n",
        "NO_OBJECT_SCALE  = 1.0\n",
        "OBJECT_SCALE     = 5.0\n",
        "COORD_SCALE      = 1.0\n",
        "WARM_UP_BATCHES  = 0\n",
        "TRUE_BOX_BUFFER  = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhL2UogRjjlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def TransformCord(bx,img):\n",
        "  Nx,Ny, Nw, Nh = bx[0]/img.shape[1], bx[1]/img.shape[0], bx[2]/img.shape[1], bx[3]/img.shape[0]\n",
        "  Nx = Nx + Nw/2\n",
        "  Ny = Ny + Nh/2\n",
        "  Nw = bx[2] / img.shape[1]\n",
        "  Nh = bx[3] / img.shape[0]\n",
        "  return Nx,Ny, Nw, Nh\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYa4_yfUyk5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def AdjustCord(bx,cx,cy):\n",
        "  cell_W = (1/GRID_W)\n",
        "  cell_H = (1/GRID_H)\n",
        "  Nx = (bx[0] - cx) / cell_W\n",
        "  Ny = (bx[1] - cy) / cell_H\n",
        "  return Nx,Ny\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGcO2eKGzE4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ReAdjustCord(bx,imgW,imgH,cx,cy):\n",
        "  cell_W = (1/GRID_W)\n",
        "  cell_H = (1/GRID_W)\n",
        "  \n",
        "  Nx = (bx[0] * cell_W) + cx \n",
        "  Ny = (bx[1] * cell_H) + cy\n",
        "  \n",
        "  Nx -= bx[2]/2 \n",
        "  Ny -= bx[3]/2 \n",
        "  \n",
        "  Nx *= imgW\n",
        "  Ny *= imgH\n",
        "  \n",
        "  Nw = bx[2] * imgW\n",
        "  Nh = bx[3] * imgH\n",
        "  return Nx,Ny, Nw, Nh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkZLFvm_lFI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "annotations = open('/content/wider_face_split/wider_face_train_bbx_gt.txt')\n",
        "lines = annotations.readlines()\n",
        "numOfLines = len(lines)\n",
        "\n",
        "def GenerateBatch(i,END):\n",
        "  Label = []\n",
        "  Images = []\n",
        "  while i<END and i < numOfLines:\n",
        "    numOfFace= int(lines[i+1])\n",
        "    if(int(numOfFace) <= GRID_H**2):\n",
        "      imgName=str(lines[i].rstrip('\\n'))\n",
        "      path = \"/content/WIDER_train/images/\"+imgName\n",
        "      img = cv2.imread(path)\n",
        "      Images.append(cv2.resize(img,(IMAGE_H, IMAGE_W),interpolation = cv2.INTER_AREA))\n",
        "      \n",
        "      visted = [0]*3000\n",
        "      liney = []\n",
        "      for y in range(GRID_H):\n",
        "        linex = []\n",
        "        for x in range(GRID_W):\n",
        "          check = False\n",
        "          StartIdx = i+2\n",
        "          \n",
        "          for k in range(StartIdx,StartIdx+numOfFace):\n",
        "            if not visted[k-StartIdx]:\n",
        "              bx = list(map(int,lines[k].split(' ')[:-1]))\n",
        "              Nx,Ny, Nw, Nh = TransformCord(bx,img)#Scale range to (0-1)\n",
        "              if((Nx > (x / GRID_W) and Nx <= ((x+1)/GRID_W))  and (Ny > (y / GRID_H) and Ny <= ((y+1)/GRID_H))):#Check if face exist in this cell\n",
        "                Nx,Ny = AdjustCord([Nx,Ny] , x/GRID_W ,  y/GRID_H)\n",
        "                # print(bx)\n",
        "                # print(Nx,Ny, Nw, Nh)\n",
        "                # print(ReAdjustCord([Nx,Ny, Nw, Nh], img.shape[1],img.shape[0], x/GRID_W, y/GRID_H))\n",
        "                # print(\"\")\n",
        "                linex.append([[Nx,Ny,Nw,Nh,1],[Nx,Ny,Nw,Nh,1],[Nx,Ny,Nw,Nh,1],[Nx,Ny,Nw,Nh,1],[Nx,Ny,Nw,Nh,1]])\n",
        "                check = True\n",
        "                visted[k-StartIdx] = 1\n",
        "                break\n",
        "       \n",
        "          if check == False:\n",
        "            linex.append([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]])\n",
        "        liney.append(linex)\n",
        "          \n",
        "      Label.append(liney)\n",
        "    i+= max(numOfFace,1)+2\n",
        "    \n",
        "  return i , np.array(Images) , np.array(Label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQKDugV3XIa1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#building classifer \n",
        "def C_N_N():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(8*baseMapNum, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                     input_shape=(IMAGE_H, IMAGE_W, 3),activation=LeakyReLU(alpha=0.1)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Conv2D(8*baseMapNum, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay),activation=LeakyReLU(alpha=0.1)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.1))\n",
        "\n",
        "    model.add(Conv2D(4 * baseMapNum, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay),activation=LeakyReLU(alpha=0.1)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Conv2D(4 * baseMapNum, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay),activation=LeakyReLU(alpha=0.1)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.1))  \n",
        "\n",
        "    model.add(Conv2D(2 * baseMapNum, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay),activation=LeakyReLU(alpha=0.1)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Conv2D(2 * baseMapNum, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay),activation=LeakyReLU(alpha=0.1)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.1))  \n",
        "    \n",
        "    model.add(Conv2D(2 * baseMapNum, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay),activation=LeakyReLU(alpha=0.1)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(4, 4)))\n",
        "    model.add(Dropout(0.1))  \n",
        "   \n",
        "    model.add(Conv2D(baseMapNum, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay),activation=LeakyReLU(alpha=0.1)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Conv2D(baseMapNum, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay),activation=LeakyReLU(alpha=0.1)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Conv2D(BOX * (4 + 1), (1,1), strides=(1,1)))\n",
        "    model.add(Reshape((GRID_H, GRID_W,BOX, 4 + 1)))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U37ACpIDXKS3",
        "colab_type": "code",
        "outputId": "dd718cde-835c-45eb-80f8-1ffeeb07df6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#compile it\n",
        "model = C_N_N()\n",
        "model.summary()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/activations.py:235: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
            "  identifier=identifier.__class__.__name__))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 440, 440, 256)     7168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 440, 440, 256)     1024      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 440, 440, 256)     590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 440, 440, 256)     1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 220, 220, 256)     0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 220, 220, 256)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 220, 220, 128)     295040    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 220, 220, 128)     512       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 220, 220, 128)     147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 220, 220, 128)     512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 110, 110, 128)     0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 110, 110, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 110, 110, 64)      73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 110, 110, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 110, 110, 64)      36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 110, 110, 64)      256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 55, 55, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 55, 55, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 55, 55, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 55, 55, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 13, 13, 32)        18464     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 13, 13, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 13, 13, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 13, 13, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 13, 13, 25)        825       \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 13, 13, 5, 5)      0         \n",
            "=================================================================\n",
            "Total params: 1,220,153\n",
            "Trainable params: 1,218,105\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ezk2WMamuda2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss(y_true, y_pred):\n",
        "    mask_shape = tf.shape(y_true)[:4]\n",
        "    print(\"Mask\",np.shape(mask_shape))\n",
        "\n",
        "    cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(GRID_W), [GRID_H]), (1, GRID_H, GRID_W, 1, 1)))\n",
        "    print(\"cell_x\",np.shape(cell_x))\n",
        "    cell_y = cell_x\n",
        "    print(\"cell_y\",np.shape(cell_y))\n",
        "\n",
        "    cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, 5, 1])\n",
        "    print(\"cell_grid\",np.shape(cell_grid))\n",
        "\n",
        "    coord_mask = tf.zeros(mask_shape)\n",
        "    conf_mask  = tf.zeros(mask_shape)\n",
        "    print(\"coord_mask\",np.shape(coord_mask))\n",
        "    \n",
        "    seen = tf.Variable(0.)\n",
        "    total_recall = tf.Variable(0.)\n",
        "    \n",
        "    \"\"\"\n",
        "    Adjust prediction\n",
        "    \"\"\"\n",
        "    ### adjust x and y      \n",
        "    pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
        "    \n",
        "    ### adjust w and h\n",
        "    pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(ANCHORS, [1,1,1,BOX,2])\n",
        "    \n",
        "    ### adjust confidence\n",
        "    pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
        "    \n",
        "    ### adjust class probabilities\n",
        "    \n",
        "    \"\"\"\n",
        "    Adjust ground truth\n",
        "    \"\"\"\n",
        "    ### adjust x and y\n",
        "    true_box_xy = y_true[..., 0:2] # relative position to the containing cell\n",
        "    \n",
        "    ### adjust w and h\n",
        "    true_box_wh = y_true[..., 2:4] # number of cells accross, horizontally and vertically\n",
        "    \n",
        "    # ### adjust confidence\n",
        "    true_wh_half = true_box_wh / 2.\n",
        "    true_mins    = true_box_xy - true_wh_half\n",
        "    true_maxes   = true_box_xy + true_wh_half\n",
        "    \n",
        "    pred_wh_half = pred_box_wh / 2.\n",
        "    pred_mins    = pred_box_xy - pred_wh_half\n",
        "    pred_maxes   = pred_box_xy + pred_wh_half       \n",
        "    print(\"pred0\",np.shape(pred_mins),np.shape(true_mins),np.shape(pred_maxes),np.shape(true_maxes))\n",
        "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
        "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "    \n",
        "    true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
        "    pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
        "\n",
        "    union_areas = pred_areas + true_areas - intersect_areas\n",
        "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
        "    print(\"iou_scores\",np.shape(iou_scores))\n",
        "    true_box_conf = iou_scores * y_true[..., 4]\n",
        "    print(\"true_box_conf\",np.shape(true_box_conf))\n",
        "\n",
        "    # true_box_conf = y_true[..., 4]\n",
        "    \n",
        "    ### adjust class probabilities\n",
        "    \n",
        "    \"\"\"\n",
        "    Determine the masks\n",
        "    \"\"\"\n",
        "    ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
        "    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * COORD_SCALE\n",
        "    \n",
        "    ### confidence mask: penelize predictors + penalize boxes with low IOU\n",
        "    # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
        "    true_xy = y_true[..., 0:2]\n",
        "    true_wh = y_true[..., 2:4]\n",
        "    print(\"true_xy\",np.shape(true_xy),np.shape(true_wh))\n",
        "    \n",
        "    \n",
        "    true_wh_half = true_wh / 2.\n",
        "    true_mins    = true_xy - true_wh_half\n",
        "    true_maxes   = true_xy + true_wh_half\n",
        "    \n",
        "    # pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
        "    # pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
        "    # pred_xy = pred_box_xy\n",
        "    # pred_wh = pred_box_wh\n",
        "    \n",
        "    pred_wh_half = pred_box_wh / 2.\n",
        "    pred_mins    = pred_box_xy - pred_wh_half\n",
        "    pred_maxes   = pred_box_xy + pred_wh_half    \n",
        "   \n",
        "    print(\"pred\",np.shape(pred_mins),np.shape(true_mins),np.shape(pred_maxes),np.shape(true_maxes))\n",
        "\n",
        "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
        "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "    print(\"0\")\n",
        "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
        "    pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
        "    print(\"1\")\n",
        "    union_areas = pred_areas + true_areas - intersect_areas\n",
        "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
        "    print(\"iou_scores\",np.shape(iou_scores))\n",
        "    print(\"2\")\n",
        "    best_ious = tf.reduce_max(iou_scores, axis=3,keepdims=True)\n",
        "    print(\"best_ious\",np.shape(best_ious))\n",
        "    print(\"2.5\")\n",
        "    conf_mask = conf_mask + tf.to_float(best_ious < 0.6) * (1 - y_true[..., 4]) * NO_OBJECT_SCALE\n",
        "    print(\"3\")\n",
        "    # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n",
        "    conf_mask = conf_mask + y_true[..., 4] * OBJECT_SCALE\n",
        "        \n",
        "    \"\"\"\n",
        "    Warm-up training\n",
        "    \"\"\"\n",
        "    no_boxes_mask = tf.to_float(coord_mask < COORD_SCALE/2.)\n",
        "    seen = tf.assign_add(seen, 1.)\n",
        "    \n",
        "    true_box_xy, true_box_wh, coord_mask = tf.cond(tf.less(seen, WARM_UP_BATCHES), \n",
        "                          lambda: [true_box_xy + (0.5 + cell_grid) * no_boxes_mask, \n",
        "                                   true_box_wh + tf.ones_like(true_box_wh) * np.reshape(ANCHORS, [1,1,1,BOX,2]) * no_boxes_mask, \n",
        "                                   tf.ones_like(coord_mask)],\n",
        "                          lambda: [true_box_xy, \n",
        "                                   true_box_wh,\n",
        "                                   coord_mask])\n",
        "    \n",
        "    \"\"\"\n",
        "    Finalize the loss\n",
        "    \"\"\"\n",
        "    nb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\n",
        "    nb_conf_box  = tf.reduce_sum(tf.to_float(conf_mask  > 0.0))\n",
        "    \n",
        "    loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
        "    loss_wh    = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
        "    loss_conf  = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask)  / (nb_conf_box  + 1e-6) / 2.\n",
        "    \n",
        "    loss = loss_xy + loss_wh + loss_conf\n",
        "    \n",
        "    nb_true_box = tf.reduce_sum(y_true[..., 4])\n",
        "    nb_pred_box = tf.reduce_sum(tf.to_float(true_box_conf > 0.5) * tf.to_float(pred_box_conf > 0.3))\n",
        "\n",
        "    \"\"\"\n",
        "    Debugging code\n",
        "    \"\"\"    \n",
        "    current_recall = nb_pred_box/(nb_true_box + 1e-6)\n",
        "    total_recall = tf.assign_add(total_recall, current_recall) \n",
        "\n",
        "    loss = tf.Print(loss, [tf.zeros((1))], message='Dummy Line \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [loss_xy], message='Loss XY \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [loss_wh], message='Loss WH \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [loss_conf], message='Loss Conf \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [loss], message='Total Loss \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [current_recall], message='Current Recall \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [total_recall/seen], message='Average Recall \\t', summarize=1000)\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJJM7hNGYJlf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "ffa9e829-6077-47cf-e698-2c9a395373b3"
      },
      "source": [
        "model.compile(loss=custom_loss, optimizer=keras.optimizers.adam())"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mask (4,)\n",
            "cell_x (1, 13, 13, 1, 1)\n",
            "cell_y (1, 13, 13, 1, 1)\n",
            "cell_grid (4, 13, 13, 5, 2)\n",
            "coord_mask (?, ?, ?, ?)\n",
            "pred0 (4, 13, 13, 5, 2) (?, ?, ?, ?, ?) (4, 13, 13, 5, 2) (?, ?, ?, ?, ?)\n",
            "iou_scores (4, 13, 13, 5)\n",
            "true_box_conf (4, 13, 13, 5)\n",
            "true_xy (?, ?, ?, ?, ?) (?, ?, ?, ?, ?)\n",
            "pred (4, 13, 13, 5, 2) (?, ?, ?, ?, ?) (4, 13, 13, 5, 2) (?, ?, ?, ?, ?)\n",
            "0\n",
            "1\n",
            "iou_scores (4, 13, 13, 5)\n",
            "2\n",
            "best_ious (4, 13, 13, 1)\n",
            "2.5\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBlARwVo5XxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss(y_true, y_pred):\n",
        "    mask_shape = tf.shape(y_true)[:4]\n",
        "    print(\"Mask\",np.shape(mask_shape))\n",
        "\n",
        "    cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(GRID_W), [GRID_H]), (1, GRID_H, GRID_W, 1, 1)))\n",
        "    print(\"cell_x\",np.shape(cell_x))\n",
        "    cell_y = cell_x\n",
        "    print(\"cell_y\",np.shape(cell_y))\n",
        "\n",
        "    cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, 5, 1])\n",
        "    print(\"cell_grid\",np.shape(cell_grid))\n",
        "\n",
        "    coord_mask = tf.zeros(mask_shape)\n",
        "    conf_mask  = tf.zeros(mask_shape)\n",
        "    print(\"coord_mask\",np.shape(coord_mask))\n",
        "    \n",
        "    seen = tf.Variable(0.)\n",
        "    total_recall = tf.Variable(0.)\n",
        "    \n",
        "    \"\"\"\n",
        "    Adjust prediction\n",
        "    \"\"\"\n",
        "    pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
        "    pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(ANCHORS, [1,1,1,BOX,2])    \n",
        "    pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
        "    \"\"\"\n",
        "    Adjust ground truth\n",
        "    \"\"\"\n",
        "    true_box_xy = y_true[..., 0:2] \n",
        "    true_box_wh = y_true[..., 2:4] \n",
        "    true_box_conf = y_true[..., 4]\n",
        "    \"\"\"\n",
        "    Determine the masks\n",
        "    \"\"\"\n",
        "    ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
        "    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * COORD_SCALE\n",
        "    \"\"\"\n",
        "    Warm-up training\n",
        "    \"\"\"\n",
        "    no_boxes_mask = tf.to_float(coord_mask < COORD_SCALE/2.)\n",
        "    \n",
        "    seen = tf.assign_add(seen, 1.)\n",
        "    true_box_xy, true_box_wh, coord_mask = tf.cond(tf.less(seen, WARM_UP_BATCHES),\n",
        "                   lambda: [true_box_xy + (0.5) * no_boxes_mask, \n",
        "                   true_box_wh + tf.ones_like(true_box_wh) * np.reshape(ANCHORS, [1,1,1,BOX,2])* no_boxes_mask, tf.ones_like(coord_mask)],\n",
        "                   lambda: [true_box_xy, true_box_wh, coord_mask])\n",
        "    \n",
        " \n",
        "    \"\"\"\n",
        "    Finalize the loss\n",
        "    \"\"\"\n",
        "    nb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\n",
        "    # nb_conf_box  = tf.reduce_sum(tf.to_float(conf_mask  > 0.0))\n",
        "\n",
        "    loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
        "    loss_wh    = tf.reduce_sum(tf.square(tf.sqrt(true_box_wh)-tf.sqrt(pred_box_wh))     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
        "    loss_conf  = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf))\n",
        "    loss = loss_xy + loss_wh + loss_conf\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UffSVeMLgruQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "542a48ff-1e90-4fbb-fd7b-4935c4fe38f5"
      },
      "source": [
        "i=0\n",
        "i, x, y = GenerateBatch(i,500)\n",
        "print(i)\n",
        "x_train, x_test, y_train ,y_test = train_test_split(x, y, test_size=0.2, random_state=50)\n",
        "print(np.shape(y_train))\n",
        "# y_train = np.reshape(y_train,(len(x_train),13, 13, BOX, 5))\n",
        "# print(np.shape(y_train))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "516\n",
            "(13, 13, 13, 5, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbSbCkibhKqH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "227df91f-4864-4333-c138-81a98e566d71"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=50, batch_size=BATCH_SIZE, validation_data=(x_test,y_test), verbose=1)\n",
        "model.save_weights(\"/content/drive/My Drive/WiderFaceweights2.h5\")"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13 samples, validate on 4 samples\n",
            "Epoch 1/50\n",
            "13/13 [==============================] - 2s 149ms/step - loss: 136.5662 - val_loss: 2068431.6250\n",
            "Epoch 2/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 316.8434 - val_loss: 33.4964\n",
            "Epoch 3/50\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 70.5530 - val_loss: 32.9947\n",
            "Epoch 4/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 69.7531 - val_loss: 33.0097\n",
            "Epoch 5/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 69.8137 - val_loss: 33.1308\n",
            "Epoch 6/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 61.0399 - val_loss: 33.2666\n",
            "Epoch 7/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 82.9978 - val_loss: 33.1725\n",
            "Epoch 8/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 77.9098 - val_loss: nan\n",
            "Epoch 9/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 118.2222 - val_loss: nan\n",
            "Epoch 10/50\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 146.9846 - val_loss: nan\n",
            "Epoch 11/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 142.4385 - val_loss: nan\n",
            "Epoch 12/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 65.9976 - val_loss: nan\n",
            "Epoch 13/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 59.3393 - val_loss: nan\n",
            "Epoch 14/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 54.2287 - val_loss: nan\n",
            "Epoch 15/50\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 67.9233 - val_loss: nan\n",
            "Epoch 16/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 55.0461 - val_loss: nan\n",
            "Epoch 17/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 69.2132 - val_loss: 32.9383\n",
            "Epoch 18/50\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 69.0175 - val_loss: 32.9259\n",
            "Epoch 19/50\n",
            "13/13 [==============================] - 1s 109ms/step - loss: 71.0810 - val_loss: 32.9082\n",
            "Epoch 20/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 58.5046 - val_loss: 32.9001\n",
            "Epoch 21/50\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 58.3887 - val_loss: 32.9005\n",
            "Epoch 22/50\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 63.9695 - val_loss: 32.9088\n",
            "Epoch 23/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 62.9948 - val_loss: 32.9172\n",
            "Epoch 24/50\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 58.9426 - val_loss: 32.9222\n",
            "Epoch 25/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 58.2465 - val_loss: 32.9263\n",
            "Epoch 26/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 60.2818 - val_loss: 32.9343\n",
            "Epoch 27/50\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 52.9766 - val_loss: 32.9439\n",
            "Epoch 28/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 58.6298 - val_loss: 32.9528\n",
            "Epoch 29/50\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 60.1142 - val_loss: 32.9640\n",
            "Epoch 30/50\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 56.6313 - val_loss: 32.9754\n",
            "Epoch 31/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 53.0784 - val_loss: 32.9895\n",
            "Epoch 32/50\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 56.4166 - val_loss: 33.0098\n",
            "Epoch 33/50\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 56.6719 - val_loss: 33.0323\n",
            "Epoch 34/50\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 63.7863 - val_loss: 33.0581\n",
            "Epoch 35/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 51.8966 - val_loss: 33.0857\n",
            "Epoch 36/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 53.8529 - val_loss: 33.1210\n",
            "Epoch 37/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 57.1877 - val_loss: 33.1679\n",
            "Epoch 38/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 55.8706 - val_loss: 33.2282\n",
            "Epoch 39/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 55.7928 - val_loss: 33.3033\n",
            "Epoch 40/50\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 49.0636 - val_loss: 33.3747\n",
            "Epoch 41/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 55.1549 - val_loss: 33.4472\n",
            "Epoch 42/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 53.8157 - val_loss: 33.5375\n",
            "Epoch 43/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 52.8505 - val_loss: 33.5994\n",
            "Epoch 44/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 63.5919 - val_loss: 33.6796\n",
            "Epoch 45/50\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 56.2528 - val_loss: 33.8027\n",
            "Epoch 46/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 52.1852 - val_loss: 33.8777\n",
            "Epoch 47/50\n",
            "13/13 [==============================] - 1s 107ms/step - loss: 56.0676 - val_loss: 34.0260\n",
            "Epoch 48/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 53.7497 - val_loss: 34.1765\n",
            "Epoch 49/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 53.0765 - val_loss: 34.3489\n",
            "Epoch 50/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 57.2017 - val_loss: 34.5532\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1kDQX9a78Kx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(np.exp(0.5))\n",
        "print(np.log(np.exp(0.05)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfcF9W289Mwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + math.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDImVYEEGN9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, tempx, ty = GenerateBatch(0,1000)\n",
        "img = tempx[0]\n",
        "true_box_wh = ty[..., 2:4]\n",
        "print(np.shape(true_box_wh))\n",
        "i = ty[0].reshape((GRID_H * GRID_W,5))[67]\n",
        "print(i)\n",
        "# Nx,Ny, Nw, Nh = ReAdjustCord(i[0]*(8/GRID_W),i[1]*(5/GRID_H), i[2], i[3],img)\n",
        "# cv2.rectangle(img, (int(Nx),int(Ny)), (int(Nw)+int(Nx),int(Nh)+int(Ny)), (255,0,0)) \n",
        "# cv2_imshow(img)\n",
        "# print(Nx,Ny, Nw, Nh)\n",
        "tempy = model.predict(tempx)\n",
        "i = tempy[0].reshape((GRID_H * GRID_W,5))[67]\n",
        "Nx,Ny, Nw, Nh = sigmoid(i[0]),sigmoid(i[1]), np.exp(i[2]), np.exp(i[3])\n",
        "print(Nx,Ny, Nw, Nh)\n",
        "Nx,Ny, Nw, Nh = ReAdjustCord(Nx*(8/GRID_W),Ny*(5/GRID_H), Nw, Nh,img)\n",
        "print(Nx,Ny, Nw, Nh)\n",
        "cv2.rectangle(img, (int(Nx),int(Ny)), (int(Nw)+int(Nx),int(Nh)+int(Ny)), (255,0,0)) \n",
        "cv2_imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWehiqRzfYEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(GRID_H * GRID_W):\n",
        "  tt = ty[0].reshape((GRID_H * GRID_W,5))[i]\n",
        "  if(tt[4] > 0.5):\n",
        "    print(tt)\n",
        "    print(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYnSBKqoBa6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, tempx, ty = GenerateBatch(0,1000)\n",
        "tempy = model.predict(tempx)\n",
        "img = tempx[0]\n",
        "print(np.shape(tempy[0]))\n",
        "for idx,i in enumerate(ty[0].reshape((9,5))):\n",
        "    if(float(i[4]) > 0.5):\n",
        "      print(\"ssss\",i,idx)\n",
        "      Nx,Ny, Nw, Nh = sigmoid(i[0]),sigmoid(i[1]), i[2], i[3]\n",
        "      print(Nx,Ny, Nw, Nh)\n",
        "      Nx,Ny, Nw, Nh = ReAdjustCord(i[0],i[1], i[2], i[3],img)\n",
        "      print(Nx,Ny, Nw, Nh)\n",
        "      cv2.rectangle(img, (int(Nx),int(Ny)), (int(Nw)+int(Nx),int(Nh)+int(Ny)), (255,0,0)) \n",
        "      cv2_imshow(img)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMX3asX1To4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(\"/content/drive/My Drive/Face Detection/weights.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CJ0dR2tWGw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predicted = model.predict(x)\n",
        "# predicted = np.reshape(predicted,(1,3*3,5))\n",
        "# for i in predicted[0]:\n",
        "#   if(float(i[0]) > 0.5):\n",
        "#     print(i)\n",
        "# print(np.sum(predicted,axis = 1))\n",
        "# print(np.sum(np.reshape(y,(1,3*3,5)),axis = 1))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}